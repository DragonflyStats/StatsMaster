

\section{Information Theory}

\subsection*{Question 61. (27 marks) }
A source language has 5 symbols A, B, C, D and E. The associated
probabilities of these symbols are given in the table below:
\begin{center}
	\begin{tabular}{|c|c|}
		\hline
		% after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
		Symbol & Probability \\ \hline
		A & 0.60 \\
		B & 0.30 \\
		C & 0.05 \\
		D & 0.03 \\
		E & 0.02 \\
		\hline
	\end{tabular}
\end{center}

\begin{itemize}
	\item[a.](5 marks) Calculate the entropy of the source language.
	\item[b.](10 marks) Define a Huffman binary code for the source language.
	\item[c.](3 marks) Calculate the efficiency of the code in (b) above.
	\item[d.](2 marks) Calculate the redundancy of the code in (b) above.
	\item[e.](2 marks) Briefly state what is meant by the Prefix Condition.
\end{itemize}

\subsection*{Question 62. (3 marks) } For each of the following codes state whether they are
\begin{itemize}
	\item[a.] (1 mark) nonÂ—singular
	\item[b.] (1 mark) uniquely decodable
	\item[c.] (1 mark) instantaneous
\end{itemize}
\begin{center}
	\begin{tabular}{|c|c|c|c|}
		\hline
		% after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
		& Code 1 & Code 2 & Code 3 \\
		A & 1 & 10 & 1 \\
		B & 01 & 01 & 00 \\
		C & 001 & 10 & 000 \\
		\hline
	\end{tabular}
\end{center}

\subsection*{Question 63. (10 marks) } Consider a data source drawn from an alphabet (A, B, C, D) with probability
distribution (0.3, 0.4, 0.2, 0.1).
\begin{itemize}
	\item[a.] Derive a fixed length binary code and a Huffman code for the source.
	\item[b.] Comment on the difference in shape of a binary tree representing the fixed
	length code and the Huffman tree for the source.
	\item[c.] Discuss which code is closer to the optimal. Show all your work to justify your
	answer.
\end{itemize}


