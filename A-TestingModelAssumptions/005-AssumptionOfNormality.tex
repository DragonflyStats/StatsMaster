 \documentclass[a4paper,12pt]{article}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{eurosym}
\usepackage{vmargin}
\usepackage{amsmath}
\usepackage{enumerate}
\usepackage{multicol}
\usepackage{graphics}
\usepackage{epsfig}
\usepackage{framed}
\usepackage{subfigure}
\usepackage{fancyhdr}

\setcounter{MaxMatrixCols}{10}
%TCIDATA{OutputFilter=LATEX.DLL}
%TCIDATA{Version=5.00.0.2570}
%TCIDATA{<META NAME="SaveForMode" CONTENT="1">}
%TCIDATA{LastRevised=Wednesday, February 23, 2011 13:24:34}
%TCIDATA{<META NAME="GraphicsSave" CONTENT="32">}
%TCIDATA{Language=American English}

%\pagestyle{fancy}
\setmarginsrb{20mm}{0mm}{20mm}{25mm}{12mm}{11mm}{0mm}{11mm}
%\lhead{MA4413 2013} \rhead{Mr. Kevin O'Brien}
%\chead{Midterm Assessment 1 }
%\input{tcilatex}

\begin{document}

\subsection{Logarithmic  Transformation}

If data deviate substantially from a Gaussian distribution, using a nonparametric test is not the only alternative. Consider transforming the data to create a Gaussian distribution. Transforming to reciprocals or logarithms are often helpful.
Data can fail a normality test because of the presence of an outlier. Removing that outlier can restore normality.
The decision of whether to use a parametric or nonparametric test is most important with small data sets (since the power of nonparametric tests is so low). But with small data sets, normality tests have little power to detect non-normal distributions, so an automatic approach would give you false confidence.

With large data sets, normality tests can be too sensitive. A low p-value from a normality test tells you that there is strong evidence that the data are not sampled from an ideal normal distribution. But you already know that, as almost no scientifically relevant variables form an ideal normal distribution. What you want to know is whether the distribution deviates enough from the normal ideal to invalidate conventional statistical tests (that assume a Gaussian distribution). A normality test does not answer this question. With large data sets, trivial deviations from the idea can lead to a small p-value.

\section{Outliers}
If the outlier test identifies one or more values as being an outlier, we must consider the following

1.	Was the outlier value entered into the computer incorrectly?
If the "outlier" is in fact a typo, fix it. It is always worth going back to the original data source, and checking that outlier value entered into Prism is actually the value you obtained from the experiment. If the value was the result of calculations, check for math errors.

2.	Is the outlier value scientifically impossible?
Of course you should remove outliers from your data when the value is completely impossible. Examples include a negative weight, or an age (of a person) that exceed 150 years. Those are clearly errors, and leaving erroneous values in the analysis would lead to nonsense results.

3.	Is the assumption of a Normal distribution dubious?
The Grubbs' tests assume that all the values are sampled from a Gaussian distribution, with the possible exception of one (or a few) outliers from a different distribution. If the underlying distribution is not Gaussian, then the results of the outlier test is unreliable. It is especially important to beware of lognormal distributions. If the data are sampled from a lognormal distribution, you expect to find some very high values which can easily be mistaken for outliers. Removing these values would be a mistake.

4.	Is the outlier value potentially scientifically interesting?
If each value is from a different animal or person, identifying an outlier might be important. Just because a value is not from the same normal distribution as the rest doesn't mean it should be ignored. An interesting phenomenon may have been discovered. Don't discard  the data as an outlier without considering if the observation is potentially scientifically interesting. 

5.	 Do the data records indicate any sort of experimental problem with that value
It is easier to justify removing a value from the data set when it is not only tagged as an "outlier" by an outlier test, but you also recorded problems with that value when the experiment was performed.
6.	 Do you have a policy on when to remove outliers?
Ideally, removing an outlier should not be an ad hoc decision. In general , you should follow a policy, and apply that policy consistently.

7.	 If you are looking for two or more outliers, could masking be a problem?
\textbf{\texttt{Masking}} is the name given to the problem where the presence of two (or more) outliers, can make it harder to find even a single outlier.

If you answered no to all those questions.
If you've answered no to all the questions above, there are two possibilities:
The suspect value came from the same normal population as the other values. You just happened to collect a value from one of the tails of that distribution.
	
The suspect value came from a different distribution than the rest. Perhaps it was due to a mistake, such as bad pipetting, voltage spike, holes in filters, etc. 

If you knew the first possibility was the case, you would keep the value in your analyses. Removing it would be a mistake.
If you knew the second possibility was the case, you would remove it, since including an erroneous value in your analyses will give invalid results. 

The problem, of course, is that you can never know for sure which of these possibilities is correct. An outlier test cannot answer that question for sure. Ideally, you should create a lab policy for how to deal with such data, and follow it consistently.
If you don't have a lab policy on removing outliers, here is suggestion: Analyze your data both with and without the suspected outlier. If the results are similar either way, you've got a clear conclusion. If the results are very different, then you are stuck. Without a consistent policy on when you remove outliers, you are likely to only remove them when it helps push the data towards the results you want.


\subsection{Grubbs’ Test}
Grubbs' test is a formal hypothesis test for assessing whether or not a  data set contains an outlier.
This data set is univariate and approximately normal distributed. This test is designed for assessing one outlier only.  If more outliers are suspected, alternative tests, such as the Tietjen-Moore test, are recommended.
Hypotheses: Grubbs' test is defined for the hypothesis: 
\begin{description}
\item[Ho] :  There are no outliers in the data set  
\item[Ha] :  There is exactly one outlier in the data set  
\end{description}

\begin{framed}
\begin{verbatim}
install.packages("outliers")
library(outliers)
#Package Author : Lukasz Komsta (UMLUB, Poland)

grubbs.test(DAT002)
\end{verbatim}
\end{framed}



\section{Non-Parametric Tests}
Many statistical tests assume that you have sampled data from populations that follow a Normal distribution. 
Biological data never follow a Gaussian distribution precisely, because a Gaussian distribution extends infinitely in both directions, and so it includes both infinitely low negative numbers and infinitely high positive numbers. But many kinds of biological data follow a bell-shaped distribution that is approximately Gaussian. 

Because statistical tests work well even if the distribution is only approximately Gaussian (especially with large samples), these tests are used routinely in many fields of science.

An alternative approach does not assume that data follow a Gaussian distribution. These tests, called nonparametric tests, are appealing because they require fewer assumptions about the distribution of the data. In this approach, values are ranked from low to high, and the analyses are based on the distribution of ranks.
Often, the analysis will be one of a series of experiments. Since you want to analyze all the experiments the same way, you cannot rely on the results from a single normality test.

\section*{Assumption of Normality}
%===============================%
 \begin{itemize}
\item One of the assumptions of many statistical procedures (including the t-test) is that the population from which you are sampling is normally distributed. The t-test is said to be rather ‘robust’ in terms of this 
assumption, which means that reality can deviate from this assumption a fair amount without seriously affecting the validity of the analysis. 
\item  
This is particularly true when the size of the samples is large (thanks to the Central Limit Theorem). Some deviations from normality can pose a problem for the t-test, specifically those that involve getting extreme 
scores more frequently than you would if the distribution were normal. Statistical Software Packages provides two statistical tests for deviation 
from normality, the 'Kolomogorov-Smirnov' family of tests and the 'Shapiro-Wilk' test. The 'Kolomogorov-Smirnov' test can be used to test if two data sets are distributed according to the same distribution. It can also be used to test if one data set comes from a specified distribution, such as the normal distribution. ( As such, the normal distribution must be specified as an  argument to the function.) 
\item 
For the purposes of this module, we will only use a special case of the 'Kolomogorov-Smirnov' test, known as the ‘ Anderson-Darling' test of 
normality. 
\item 
The \textit{\textbf{Anderson-Darling}} test can not be implemented directly in R. Using the test requires the installation of the nortest package. We will look at 
packages in greater detail later in the semester. 
\item  
The null hypothesis of both the `Anderson-Darling’ and `Shapiro-Wilk’ tests is that the population is normally distributed, and the alternative 
hypothesis is that the data is not normally distributed. 
\end{itemize} 

 
 
\section*{Graphical Methods}
\begin{itemize} 
\item The quantile-quantile (Q-Q) plot is an excellent way to see whether the data deviate from normal (the plot can be set up to see if the data 
deviate from other distributions as well but here we are only interested in the normal distribution). 
\item The process used for creating a QQ plot involves determining what proportion of the 'observed' scores fall below any one score, then the “z- 
score” that would fit that proportion if the data were normally distributed is calculated, and finally that “z- score” that would cut off that proportion 
(the 'expected normal value') is translated back into the original metric to see what raw score that would be. 
 
\item A scatter plot is then created that shows the relationship between the actual 'observed' values and what those values would be 'expected' to be 
if the data were normally distributed. If the data is normally distributed then the circles on the resulting plot (each circle representing a score) will form a straight line. 
A trend line can be added to the plot to assist in determining whether or not this relationship is linear. 
\end{itemize}
\end{document} 
 