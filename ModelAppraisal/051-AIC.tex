 \documentclass[a4paper,12pt]{article}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{eurosym}
\usepackage{vmargin}
\usepackage{amsmath}
\usepackage{enumerate}
\usepackage{multicol}
\usepackage{graphics}
\usepackage{epsfig}
\usepackage{framed}
\usepackage{subfigure}
\usepackage{fancyhdr}

\setcounter{MaxMatrixCols}{10}
%TCIDATA{OutputFilter=LATEX.DLL}
%TCIDATA{Version=5.00.0.2570}
%TCIDATA{<META NAME="SaveForMode" CONTENT="1">}
%TCIDATA{LastRevised=Wednesday, February 23, 2011 13:24:34}
%TCIDATA{<META NAME="GraphicsSave" CONTENT="32">}
%TCIDATA{Language=American English}

%\pagestyle{fancy}
\setmarginsrb{20mm}{0mm}{20mm}{25mm}{12mm}{11mm}{0mm}{11mm}
%\lhead{MA4413 2013} \rhead{Mr. Kevin O'Brien}
%\chead{Midterm Assessment 1 }
%\input{tcilatex}

\begin{document}


\section{Information Criterions}


We define two types of information criterion: the Bayesian Information
Criterion (BIC) and the Akaike Information Criterion (AIC). In AIC and BIC, we choose the model that
has the minimum value of:
\[AIC = −2log(L)+2m,\]
\[BIC = −2log(L)+mlogn\]

where
\begin{itemize}
\item L is the likelihood of the data with a certain model,
\item n is the number of observations and
\item m is the number of parameters in the model.
\end{itemize}
\subsection{AIC}
The Akaike information criterion is a measure of the relative \textbf{goodness of fit} of a statistical model.

When using the AIC for selecting the parametric model class, choose
the model for which the AIC value is lowest.
\newpage
\section{Akaike's information criterion}
\begin{itemize}
    \item Akaike's information criterion is a measure of the goodness of fit of an estimated statistical model. The AIC was developed by Hirotsugu Akaike under the name of "an information criterion" in 1971.

\item The AIC is a "model selection" tool i.e. a method of comparing two or more candidate models.

\item The AIC is calculated using the "likelihood function" and the number of parameters. (Not on course). The likelihood value is generally given in code output, as a complement to the AIC.

\item 
The AIC methodology attempts to find the model that best explains the data with a minimum of parameters. (i.e. in keeping with the Law of parsimony)

\item 
Given a data set, several competing models may be ranked according to their AIC, with the one having the lowest AIC being the best.

\item 
(A difference in AIC values of less than two is considered negligible)
\end{itemize}

\end{document} 
